# Unit 2

## Content

- Homework 1
- Homework 2
- Homework 3
- Practice 1
- Practice 2
- Practice 3
- Practice 4
- Practice 5
- Practice 6
- Evaluation
- Colaborators


## Homework 1
1. Regression algorithms
In regression tasks, the machine learning program must estimate and understand the relationships between variables. Regression analysis focuses on one dependent variable and a number of other changing variables, making it particularly useful for forecasting and forecasting.
2. Bayesian algorithms
These types of classification algorithms are based on Bayes' theorem and classify each value as independent of any other. This allows predicting a class or category based on a given set of characteristics, using probability.
Despite its simplicity, the classifier works surprisingly well and is often used because it outperforms more sophisticated classification methods.
3. Grouping algorithms
They are used in unsupervised learning, and serve to categorize unlabelled data, that is, data without defined categories or groups.
The algorithm works by searching for groups within the data, with the number of groups represented by the variable K. Next, it works iteratively to assign each data point to one of the K groups according to the characteristics provided.
4. Decision tree algorithms
A decision tree is a tree structure similar to a flowchart that uses a branching method to illustrate every possible result of a decision. Each node within the tree represents a test on a specific variable, and each branch is the result of that test.
5. Neural network algorithms
An artificial neural network (RNA) comprises units arranged in a series of layers, each of which connects to the adjacent layers. RNAs are inspired by biological systems, such as the brain, and how they process information.
Thus they are essentially a large number of interconnected processing elements, working in unison to solve specific problems.
They also learn by example and experience, and are extremely useful for modeling nonlinear relationships in high-dimensional data, or where the relationship between the input variables is difficult to understand.
6. Dimension reduction algorithms
Dimension reduction reduces the number of variables that are considered to find the exact information required
7. Deep Learning Algorithms
Deep learning algorithms execute data through several layers of neural network algorithms, which move to a simplified representation of the data to the next layer. Most work well on data sets that have up to a few hundred features or columns. However, an unstructured dataset, such as an image, has such a large number of features that this process becomes cumbersome or completely unfeasible.

## Homework 2
**VectorAssembler** is a transformer that combines a given list of columns into a single vector column. It is useful for combining raw features and features generated by different feature transformers into a single feature vector, in order to train ML models such as logistic regression and decision trees. VectorAssembler accepts the following types of input columns: all numeric types, boolean type and vector type. In each row, the values in the input columns will be concatenated into a vector in the specified order.
Root-mean-square deviation.

**The root of the root mean square error (RECM) or root of the root mean square deviation (RDCM)** is a frequently used measure of the differences between the values (sample or population values) predicted by a model or estimator and the observed values . The RECM represents the square root of the second moment of the sample of the differences between the predicted values and the observed values or the root mean of these differences. These deviations are called residuals when the calculations are made on the data sample that was used for the estimation and are called errors (or prediction errors) when they are calculated outside the sample.
